# SuperPoint UAV Fine-tuning Pipeline (FIXED)

A clean, robust implementation for fine-tuning SuperPoint on UAV/drone imagery using proven pretrained weights. **All critical training logic errors have been fixed.**

## Overview

This pipeline:

1. **Downloads** proven pretrained SuperPoint weights from established repositories
2. **Generates** high-quality UAV training data from your earth imagery
3. **Fine-tunes** only the descriptor head on UAV-specific data with proper loss functions
4. **Visualizes** matching results with clean, accurate representations

## ðŸ”§ **Recent Fixes Applied**

### Critical Issues Fixed:

- âœ… **Descriptor Normalization**: Fixed zero-descriptor bug using `F.normalize()`
- âœ… **Training Loop**: Eliminated inefficient circular dependency in keypoint detection
- âœ… **Loss Function**: Corrected backwards descriptor loss logic
- âœ… **Homography Generation**: Added validation to prevent degenerate transformations
- âœ… **Negative Sampling**: Fixed random sampling to ensure true negatives
- âœ… **Data Quality**: Added comprehensive quality checks for training crops

### Performance Improvements:

- âœ… **Efficient Keypoint Extraction**: Direct heatmap processing instead of full inference
- âœ… **Better Augmentations**: UAV-specific augmentations (noise, blur, conservative rotations)
- âœ… **Quality Control**: Gradient and texture analysis for crop selection
- âœ… **Robust Training**: Proper error handling and validation

## Quick Start

**Test the fixes first:**

```bash
python test_fixes.py
```

**Run the complete pipeline:**

```bash
python run_superpoint_pipeline.py
```

Or run individual steps:

### 1. Download Pretrained Weights

```bash
python download_pretrained_superpoint.py
```

### 2. Generate High-Quality UAV Data

```bash
python generate_uav_data.py --earth_imagery_dir data/earth_imagery --n_crops_per_location 1000
```

### 3. Train SuperPoint (Fixed)

```bash
python train_superpoint_uav.py --data_dir uav_data --pretrained_weights pretrained_weights/superpoint_v1.pth --epochs 20
```

### 4. Visualize Results

```bash
# Test with UAV data
python visualize_superpoint_clean.py --weights superpoint_uav_trained/superpoint_uav_final.pth --uav_data uav_data

# Test with specific images
python visualize_superpoint_clean.py --weights superpoint_uav_trained/superpoint_uav_final.pth --img1 image1.jpg --img2 image2.jpg
```

## Files

- `simple_superpoint.py` - **FIXED** SuperPoint implementation with proper normalization
- `train_superpoint_uav.py` - **FIXED** training script with corrected loss functions
- `generate_uav_data.py` - **IMPROVED** data generation with quality control
- `download_pretrained_superpoint.py` - Download pretrained weights
- `visualize_superpoint_clean.py` - Clean visualization of matching results
- `run_superpoint_pipeline.py` - All-in-one pipeline script
- `test_fixes.py` - Test script to verify all fixes work

## Key Features

- **Proven weights**: Uses established pretrained SuperPoint weights
- **Fixed training**: Corrected descriptor loss and normalization bugs
- **Quality control**: Comprehensive data quality assessment
- **Efficient training**: Optimized keypoint extraction and loss computation
- **UAV-focused**: Realistic UAV crops with appropriate augmentations
- **Robust homographies**: Validated transformations prevent degenerate cases
- **Clean visualization**: Shows actual SuperPoint performance

## Requirements

```bash
pip install torch opencv-python numpy tqdm requests
```

## Training Strategy (Fixed)

- âœ… Starts with proven pretrained SuperPoint weights
- âœ… Freezes encoder and detector (keypoint detection)
- âœ… Only trains descriptor head with **corrected loss function**
- âœ… Uses **validated homographic adaptation** for self-supervised learning
- âœ… **Proper descriptor normalization** prevents zero-vector issues
- âœ… **Efficient keypoint extraction** eliminates circular dependencies
- âœ… Fast training (10-20 epochs typically sufficient)

## What Was Wrong Before

1. **Zero Descriptors**: Manual normalization created division-by-zero
2. **Backwards Loss**: Loss function penalized similarity instead of encouraging it
3. **Circular Training**: Used model being trained to extract keypoints for training
4. **Degenerate Homographies**: No validation led to invalid transformations
5. **Poor Negatives**: Random sampling included true correspondences as negatives
6. **Low Quality Data**: No texture/gradient checks led to uniform crops

## What's Fixed Now

1. **Proper Normalization**: Uses `F.normalize()` with built-in epsilon handling
2. **Correct Loss**: Minimizes distance for matches, maximizes for non-matches
3. **Efficient Training**: Direct heatmap processing for keypoint extraction
4. **Validated Homographies**: Determinant checks prevent degenerate cases
5. **True Negatives**: Ensures negative samples are actually non-corresponding
6. **Quality Control**: Gradient and texture analysis ensures meaningful crops

This approach ensures robust keypoint detection while properly adapting descriptors to UAV imagery characteristics.
