data:
  # name: 'coco'
  dataset: "RSSDIVCS" # 'RSSDIVCS' /'Coco'

  labels: /home/ubuntu/drone-embeddings/third_party/superpoint-train/logs/magicpoint_synth_homoAdapt_RSSDIVCS/predictions
  #    labels: logs/magicpoint_synth_homoAdapt_coco/predictions
  root: # datasets/COCO
  root_split_txt: # /datasets/COCO

  gaussian_label:
    enable: true
    params:
      GaussianBlur: { sigma: 0.2 }

  cache_in_memory: false
  preprocessing:
    resize: [256, 256]
  #         resize: [240, 320]
  augmentation:
    photometric:
      enable: true
      primitives:
        [
          "random_brightness",
          "random_contrast",
          "additive_speckle_noise",
          "additive_gaussian_noise",
          "additive_shade",
          "motion_blur",
        ]
      params:
        random_brightness: { max_abs_change: 50 }
        random_contrast: { strength_range: [0.5, 1.5] }
        additive_gaussian_noise: { stddev_range: [0, 10] }
        additive_speckle_noise: { prob_range: [0, 0.0035] }
        additive_shade:
          transparency_range: [-0.5, 0.5]
          kernel_size_range: [100, 150]
        motion_blur: { max_kernel_size: 3 }
    homographic:
      enable: false # not implemented
  warped_pair:
    enable: true
    params:
      translation: true
      rotation: true
      scaling: true
      perspective: true
      scaling_amplitude: 0.2
      perspective_amplitude_x: 0.2
      perspective_amplitude_y: 0.2
      patch_ratio: 0.85
      max_angle: 1.57
      allow_artifacts: true # true
    valid_border_margin: 3

front_end_model: "SuperPoint_fronted" # 'Train_model_frontend'

training:
  workers_train: 28 # Use all 28 CPU cores on H100
  workers_val: 28 # Use many workers for validation

model:
  # name: 'magic_point'
  # name: 'SuperPointNet_heatmap'
  #    name: 'SuperPointNet_retrieval'
  #    name: 'SuperPointNet_gauss2'
  #    name: 'SuperPointNet_ResNet152'
  params: {}
  detector_loss:
    loss_type: "softmax"

  batch_size: 256 # Large batch size for H100
  eval_batch_size: 256 # Large eval batch size
  learning_rate: 0.0001
  detection_threshold: 0.015
  lambda_loss: 1
  nms: 4
  dense_loss:
    enable: false
    params:
      descriptor_dist: 4
      lambda_d: 800
  sparse_loss:
    enable: true
    params:
      num_matching_attempts: 1000
      num_masked_non_matches_per_match: 100
      lamda_d: 1
      dist: "cos"
      method: "2d"
  other_settings: "train 2d, gauss 0.2"
  # subpixel:
  # enable: false
  # params:
  #     subpixel_channel: 2
  # settings: 'predict flow directly'
  # loss_func: 'subpixel_loss_no_argmax' # subpixel_loss, subpixel_loss_no_argmax

retrain: Finetune
reset_iter: True
train_iter: 200000
validation_interval: 200
tensorboard_interval: 200
save_interval: 200
validation_size: 5
save_dir: logs/superpoint_rssdivcs_h100
pretrained: "/home/ubuntu/drone-embeddings/third_party/pytorch-superpoint/logs/superpoint_coco_heat2_0/checkpoints/superPointNet_170000_checkpoint.pth.tar" # Pretrained on COCO

#pretrained : '/home/lhl/data/visgeoloca/logs/default/2023-07-17_23-16-28/best_model.pth'                             # raw

#pretrained: '/home/lhl/data/superpoint-train/logs/superpoint_coco_finetune/superPointNet_11000_checkpoint.pth.tar'

